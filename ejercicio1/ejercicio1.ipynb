{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwmiASDNswJI"
   },
   "source": [
    "## **Part 1: Homography-based planar object detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxUZ09LzswJI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [40, 10] # figure size in inches\n",
    "\n",
    "def draw_images(imgs):\n",
    "    if len(imgs) > 1:\n",
    "        fig, axs = plt.subplots(1, len(imgs))\n",
    "        for idx, img in enumerate(imgs):\n",
    "            axs[idx].axis(\"off\")\n",
    "            axs[idx].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(cv2.cvtColor(imgs[0], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "filenames = [\"images/pkmn.png\", \"images/bus.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVDIS4FZswJJ",
    "outputId": "ad46c36f-9152-4b9f-b865-465504f3b87c"
   },
   "outputs": [],
   "source": [
    "# Draw images\n",
    "imgs = [cv2.imread(f) for f in filenames]\n",
    "draw_images(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWRC_K3ulqQ6"
   },
   "source": [
    "#### Detect keypoints and extract local invariant descriptors from the two input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puntos detectados con MSER y descritos con SIFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "mser = cv2.MSER_create(delta=5, min_area=60, max_area=14400)\n",
    "extractor = cv2.SIFT_create()\n",
    "\n",
    "keypoints_mser = []\n",
    "descriptors_mser = []\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    gray = cv2.cvtColor(imgs[i], cv2.COLOR_BGR2GRAY)\n",
    "    gray_eq = cv2.equalizeHist(gray)\n",
    "    \n",
    "    kp_mser = mser.detect(gray_eq, None)\n",
    "    kp_final, des = extractor.compute(imgs[i], kp_mser)\n",
    "    \n",
    "    keypoints_mser.append(kp_final)\n",
    "    descriptors_mser.append(des)\n",
    "\n",
    "detection_time = time.time() - start_time\n",
    "print(f\"Detección (MSER) y Descripción (SIFT) completada en: {detection_time:.4f} seg\")\n",
    "\n",
    "if len(keypoints_mser) >= 2 and descriptors_mser[0] is not None:\n",
    "    print(f\"Keypoints Modelo: {len(keypoints_mser[0])}, Keypoints Escena: {len(keypoints_mser[1])}\")\n",
    "\n",
    "# Draw key points\n",
    "_imgs = copy.deepcopy(imgs)\n",
    "for idx in range(len(_imgs)):\n",
    "    cv2.drawKeypoints(_imgs[idx], keypoints_mser[idx], _imgs[idx], (0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "draw_images(_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción con ORB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "detector = cv2.ORB_create(nfeatures=30000) \n",
    "keypoints_orb = []\n",
    "descriptors_orb = []\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    kp, des = detector.detectAndCompute(imgs[i], None)\n",
    "    keypoints_orb.append(kp)\n",
    "    descriptors_orb.append(des)\n",
    "\n",
    "detection_time = time.time() - start_time\n",
    "print(f\"Detección y Descripción (ORB) completada en: {detection_time:.4f} seg\")\n",
    "print(f\"Keypoints Modelo: {len(keypoints_orb[0])}, Keypoints Escena: {len(keypoints_orb[1])}\")\n",
    "\n",
    "# Draw key points\n",
    "_imgs = copy.deepcopy(imgs)\n",
    "for idx in range(len(_imgs)):\n",
    "    cv2.drawKeypoints(_imgs[idx], keypoints_orb[idx], _imgs[idx], (0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "draw_images(_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detección y descripción con SIFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOVz4YPQswJK",
    "outputId": "a294b4f3-d92a-486d-f48e-f114668015b8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "detector = cv2.SIFT_create()\n",
    "keypoints_sift = []\n",
    "descriptors_sift = []\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    kp, des = detector.detectAndCompute(imgs[i], None)\n",
    "    keypoints_sift.append(kp)\n",
    "    descriptors_sift.append(des)\n",
    "\n",
    "detection_time = time.time() - start_time\n",
    "print(f\"Detección y Descripción (SIFT) completada en: {detection_time:.4f} seg\")\n",
    "print(f\"Keypoints Modelo: {len(keypoints_sift[0])}, Keypoints Escena: {len(keypoints_sift[1])}\")\n",
    "\n",
    "# Draw key points\n",
    "_imgs = copy.deepcopy(imgs)\n",
    "for idx in range(2):\n",
    "    cv2.drawKeypoints(_imgs[idx], keypoints_sift[idx], _imgs[idx], (0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "draw_images(_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94Z6IORql08A"
   },
   "source": [
    "#### Match the descriptors between the two images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching con FLANN (KD-Tree) de los puntos encontrados con MSER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "knn_matches_mser = matcher.knnMatch(descriptors_mser[0], descriptors_mser[1], k=2)\n",
    "\n",
    "match_time = time.time() - start_time\n",
    "print(f\"Matching completado en: {match_time:.4f} seg. Matches buenos encontrados: {len(knn_matches_mser)}\")\n",
    "\n",
    "# Draw all matches\n",
    "img = cv2.drawMatchesKnn(imgs[0], keypoints_mser[0], imgs[1], keypoints_mser[1], knn_matches_mser, None, flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "draw_images([img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching con FLANN (LSH) de los puntos descritos con ORB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1) \n",
    "search_params = dict(checks=50)\n",
    "\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "knn_matches_orb = matcher.knnMatch(descriptors_orb[0], descriptors_orb[1], k=2)\n",
    "\n",
    "match_time = time.time() - start_time\n",
    "print(f\"Matching ORB completado en: {match_time:.4f} seg. Matches buenos: {len(knn_matches_orb)}\")\n",
    "\n",
    "# Draw all matches\n",
    "img_matches = cv2.drawMatchesKnn(imgs[0], keypoints_orb[0], imgs[1], keypoints_orb[1], knn_matches_orb, None, flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "draw_images([img_matches])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching con FLANN (KD-Tree) de los puntos detectados y descritos con SIFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szQgWf5dswJK",
    "outputId": "fb9a5b80-82f8-405a-ccc4-5789d9e41b0d"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "knn_matches_sift = matcher.knnMatch(descriptors_sift[0], descriptors_sift[1], k=2)\n",
    "\n",
    "match_time = time.time() - start_time\n",
    "print(f\"Matching completado en: {match_time:.4f} seg. Matches buenos encontrados: {len(knn_matches_sift)}\")\n",
    "\n",
    "# Draw all matches\n",
    "img = cv2.drawMatchesKnn(imgs[0], keypoints_sift[0], imgs[1], keypoints_sift[1], knn_matches_sift, None, flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "draw_images([img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a hacer matching pero usando fuerza bruta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSER\n",
    "start_time = time.time()\n",
    "\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "knn_matches_mser_bf = matcher.knnMatch(descriptors_mser[0], descriptors_mser[1], k=2)\n",
    "\n",
    "match_time = time.time() - start_time\n",
    "print(f\"Matching MSER (Brute Force) completado en: {match_time:.4f} seg. Matches encontrados: {len(knn_matches_mser_bf)}\")\n",
    "\n",
    "img = cv2.drawMatchesKnn(\n",
    "    imgs[0], keypoints_mser[0], \n",
    "    imgs[1], keypoints_mser[1], \n",
    "    knn_matches_mser_bf, \n",
    "    None, \n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT\n",
    ")\n",
    "\n",
    "draw_images([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORB\n",
    "start_time = time.time()\n",
    "\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "knn_matches_orb_bf = matcher.knnMatch(descriptors_orb[0], descriptors_orb[1], k=2)\n",
    "\n",
    "match_time = time.time() - start_time\n",
    "\n",
    "print(f\"Matching ORB (Brute Force) completado en: {match_time:.4f} seg. Matches encontrados: {len(knn_matches_orb_bf)}\")\n",
    "\n",
    "img_matches = cv2.drawMatchesKnn(\n",
    "    imgs[0], keypoints_orb[0], \n",
    "    imgs[1], keypoints_orb[1], \n",
    "    knn_matches_orb_bf, \n",
    "    None, \n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT\n",
    ")\n",
    "    \n",
    "draw_images([img_matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT\n",
    "start_time = time.time()\n",
    "\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "knn_matches_sift_bf = matcher.knnMatch(descriptors_sift[0], descriptors_sift[1], k=2)\n",
    "\n",
    "match_time = time.time() - start_time\n",
    "print(f\"Matching (Brute Force) completado en: {match_time:.4f} seg. Matches encontrados: {len(knn_matches_sift_bf)}\")\n",
    "\n",
    "img = cv2.drawMatchesKnn(\n",
    "    imgs[0], keypoints_sift[0], \n",
    "    imgs[1], keypoints_sift[1], \n",
    "    knn_matches_sift_bf, \n",
    "    None, \n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT\n",
    ")\n",
    "\n",
    "draw_images([img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacemos Ratio Test para eliminar matches incorrectos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSER\n",
    "good_matches_mser = []\n",
    "for m, n in knn_matches_mser:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_matches_mser.append(m)\n",
    "\n",
    "img = cv2.drawMatches(imgs[0], keypoints_mser[0], imgs[1], keypoints_mser[1], good_matches_mser, None, flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "draw_images([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORB\n",
    "good_matches_orb = []\n",
    "for m, n in knn_matches_orb:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_matches_orb.append(m)\n",
    "\n",
    "img = cv2.drawMatches(imgs[0], keypoints_orb[0], imgs[1], keypoints_orb[1], good_matches_orb, None, flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "draw_images([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT\n",
    "good_matches_sift = []\n",
    "for m, n in knn_matches_sift:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_matches_sift.append(m)\n",
    "\n",
    "img = cv2.drawMatches(imgs[0], keypoints_sift[0], imgs[1], keypoints_sift[1], good_matches_sift, None, flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "draw_images([img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DK_sD7-Wl_q3"
   },
   "source": [
    "#### Use the RANSAC algorithm to estimate a homography matrix H using the matched feature vectors and draw correct matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSER\n",
    "if len(good_matches_mser) > 4: \n",
    "    src_pts = np.float32([keypoints_mser[0][m.queryIdx].pt for m in good_matches_mser]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints_mser[1][m.trainIdx].pt for m in good_matches_mser]).reshape(-1, 1, 2)\n",
    "\n",
    "    H_mser, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Draw correct matches\n",
    "    draw_params = dict(matchColor=(0,255,0), singlePointColor=None, matchesMask=mask.ravel().tolist(), flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "    img_inliers = cv2.drawMatches(imgs[0], keypoints_mser[0], imgs[1], keypoints_mser[1], good_matches_mser, None, matchesThickness=3, **draw_params)\n",
    "    draw_images([img_inliers])\n",
    "    \n",
    "else:\n",
    "    print(\"No hay suficientes matches para calcular la homografía.\")\n",
    "    H_mser = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORB\n",
    "if len(good_matches_orb) > 4:\n",
    "    src_pts = np.float32([keypoints_orb[0][m.queryIdx].pt for m in good_matches_orb]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints_orb[1][m.trainIdx].pt for m in good_matches_orb]).reshape(-1, 1, 2)\n",
    "\n",
    "    H_orb, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Draw correct matches\n",
    "    draw_params = dict(matchColor=(0,255,0), singlePointColor=None, matchesMask=mask.ravel().tolist(), flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "    img_inliers = cv2.drawMatches(imgs[0], keypoints_orb[0], imgs[1], keypoints_orb[1], good_matches_orb, None, matchesThickness=3, **draw_params)\n",
    "    draw_images([img_inliers])\n",
    "\n",
    "else:\n",
    "    print(\"No hay suficientes matches para calcular la homografía.\")\n",
    "    H_orb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWZwqxOgswJL",
    "outputId": "19026659-0681-4525-e3c9-da03bbee29d7"
   },
   "outputs": [],
   "source": [
    "# SIFT\n",
    "if len(good_matches_sift) > 4: \n",
    "    src_pts = np.float32([keypoints_sift[0][m.queryIdx].pt for m in good_matches_sift]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints_sift[1][m.trainIdx].pt for m in good_matches_sift]).reshape(-1, 1, 2)\n",
    "\n",
    "    H_sift, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Draw correct matches\n",
    "    draw_params = dict(matchColor=(0,255,0), singlePointColor=None, matchesMask=mask.ravel().tolist(), flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "    img_inliers = cv2.drawMatches(imgs[0], keypoints_sift[0], imgs[1], keypoints_sift[1], good_matches_sift, None, matchesThickness=3, **draw_params)\n",
    "    draw_images([img_inliers])\n",
    "    \n",
    "else:\n",
    "    print(\"No hay suficientes matches para calcular la homografía.\")\n",
    "    H_sift = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiX4N5CHmM4g"
   },
   "source": [
    "#### Once camera resectioning is done from an estimated homography, this information is used to insert another image, with the correct perspective, appearing to be part of the original scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orLogLa2swJL",
    "outputId": "e2fd7007-29ff-4491-da14-cd9fd7b6f25a"
   },
   "outputs": [],
   "source": [
    "# SIFT\n",
    "if H_sift is not None:\n",
    "    img_replace = cv2.imread(\"images/ayto.png\")\n",
    "    h_model, w_model = imgs[0].shape[:2]\n",
    "    \n",
    "    img_replace_resized = cv2.resize(img_replace, (w_model, h_model))\n",
    "    \n",
    "    h_scene, w_scene = imgs[1].shape[:2]\n",
    "    proj_img = cv2.warpPerspective(img_replace_resized, H_sift, (w_scene, h_scene))\n",
    "    \n",
    "    mask_model = np.ones((h_model, w_model), dtype=np.uint8) * 255\n",
    "    mask_warped = cv2.warpPerspective(mask_model, H_sift, (w_scene, h_scene))\n",
    "    \n",
    "    scene_img = imgs[1].copy()\n",
    "    \n",
    "    mask_warped_inv = cv2.bitwise_not(mask_warped)\n",
    "    scene_bg = cv2.bitwise_and(scene_img, scene_img, mask=mask_warped_inv)\n",
    "    \n",
    "    overlay_fg = cv2.bitwise_and(proj_img, proj_img, mask=mask_warped)\n",
    "    \n",
    "    overlay = cv2.add(scene_bg, overlay_fg)\n",
    "\n",
    "    draw_images([imgs[1], proj_img, overlay])\n",
    "else:\n",
    "    print(\"No se pudo realizar el overlay por falta de homografía.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "QwmiASDNswJI",
    "wVxC2mS5swJL",
    "tQcwThP3swJN",
    "as_Y7cw2qAe3"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
